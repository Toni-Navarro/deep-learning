{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled1.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPfuVGnS9YTfHN+pzScWBSX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Toni-Navarro/deep-learning/blob/master/Improving%20my%20first%20model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W0D2WC2CJkPc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ZH3FMjKJqAE",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "#Improving my first deep learning model\n",
        "\n",
        "We will use the preload data set from keras with several images of different handwritten digits in order to build a neural net model to identify them. We will modify the parameter to reach better accuracy\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A8LI35ujJrz-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "b28b3a63-2e25-4b8d-b084-aa39d1d724ce"
      },
      "source": [
        "#Preparation of the model environment\n",
        "\n",
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print(tf.__version__)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 2.x selected.\n",
            "2.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xtItbzl1J5zg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Loading the data\n",
        "mnist = tf.keras.datasets.mnist\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Mm3tNL5dwd4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "facbd640-2566-4ca6-c6da-14f79e75eca7"
      },
      "source": [
        "print(x_train.shape)\n",
        "print(y_train.shape)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 28, 28)\n",
            "(60000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R5hdPrX90C3q",
        "colab_type": "text"
      },
      "source": [
        "**Why should the data be shuffled for machine learning tasks**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qqK92HAEfCoe",
        "colab_type": "text"
      },
      "source": [
        "The process of training a neural network is to find the minimum value of a loss function LX(W), where W represents a matrix (or several matrices) of weights between neurons and X represents the training dataset. I use a subscript for X to indicate that our minimization of L occurs only over the weights W (that is, we are looking for W such that L is minimized) while X\n",
        "\n",
        "is fixed.\n",
        "\n",
        "Now, if we assume that we have P\n",
        "elements in W (that is, there are P weights in the network), L is a surface in a P+1-dimensional space. To give a visual analogue, imagine that we have only two neuron weights (P=2). Then L has an easy geometric interpretation: it is a surface in a 3-dimensional space. This arises from the fact that for any given matrices of weights W, the loss function can be evaluated on X\n",
        "\n",
        "and that value becomes the elevation of the surface.\n",
        "\n",
        "But there is the problem of non-convexity; the surface I described will have numerous local minima, and therefore gradient descent algorithms are susceptible to becoming \"stuck\" in those minima while a deeper/lower/better solution may lie nearby. This is likely to occur if X\n",
        "is unchanged over all training iterations, because the surface is fixed for a given X\n",
        "\n",
        "; all its features are static, including its various minima.\n",
        "\n",
        "A solution to this is mini-batch training combined with shuffling. By shuffling the rows and training on only a subset of them during a given iteration, X\n",
        "changes with every iteration, and it is actually quite possible that no two iterations over the entire sequence of training iterations and epochs will be performed on the exact same X. The effect is that the solver can easily \"bounce\" out of a local minimum. Imagine that the solver is stuck in a local minimum at iteration i with training mini-batch Xi. This local minimum corresponds to L evaluated at a particular value of weights; we'll call it LXi(Wi). On the next iteration the shape of our loss surface actually changes because we are using Xi+1, that is, LXi+1(Wi) may take on a very different value from LXi(Wi) and it is quite possible that it does not correspond to a local minimum! We can now compute a gradient update and continue with training. To be clear: the shape of LXi+1 will -- in general -- be different from that of LXi. Note that here I am referring to the loss function L evaluated on a training set X; it is a complete surface defined over all possible values of W, rather than the evaluation of that loss (which is just a scalar) for a specific value of W\n",
        "\n",
        ". Note also that if mini-batches are used without shuffling there is still a degree of \"diversification\" of loss surfaces, but there will be a finite (and relatively small) number of unique error surfaces seen by the solver (specifically, it will see the same exact set of mini-batches -- and therefore loss surfaces -- during each epoch).\n",
        "\n",
        "One thing I deliberately avoided was a discussion of mini-batch sizes, because there are a million opinions on this and it has significant practical implications (greater parallelization can be achieved with larger batches). However, I believe the following is worth mentioning. Because L\n",
        "is evaluated by computing a value for each row of X (and summing or taking the average; i.e., a commutative operator) for a given set of weight matrices W, the arrangement of the rows of X has no effect when using full-batch gradient descent (that is, when each batch is the full X, and iterations and epochs are the same thing)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bKh3UrCe0VwS",
        "colab_type": "text"
      },
      "source": [
        "batch and shuffle the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TfTsl_mRdwoA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_ds = tf.data.Dataset.from_tensor_slices(\n",
        "    (x_train, y_train)).shuffle(10000).batch(32)\n",
        "\n",
        "test_ds = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(32)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HMy4HgMFdwvw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tPX3P-KGdwys",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "myvkMN8Pdw1Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RQ_i9RGqdw4A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H26_ZZLUdw6m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ARUBZ4Ndw9S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FH6Tv_DudxAR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aqsmy1H5dxDX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NSy2x_7IdxGF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dalaPxrOdxI6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bx3fcJi-KImX",
        "colab_type": "text"
      },
      "source": [
        "Preparing the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nyyN73q1KMe6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#First, we are going to transform data type from integer to float in order to normalize after that to get all values between 0 and 1\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "\n",
        "x_train /= 255\n",
        "x_test /= 255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l5XuFWEYKNie",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "15f2a2c6-1034-4d18-a705-9dda2c8c905d"
      },
      "source": [
        "#Now we are going to change the different images to concat all their lines to transform them to a single line\n",
        "x_train = x_train.reshape(60000, 784)\n",
        "x_test = x_test.reshape(10000, 784)\n",
        "\n",
        "print(x_train.shape)\n",
        "print(x_test.shape)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 784)\n",
            "(10000, 784)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "edgt_JiXKPQn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Let's use keras method \"to_categorical\"\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "y_train = to_categorical(y_train, num_classes=10)\n",
        "y_test = to_categorical(y_test, num_classes=10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aFhy54YbK4oP",
        "colab_type": "text"
      },
      "source": [
        "Defining the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CptjSiKuK5V6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Our model will be sequential with a conv2d lay and relu activation, another lay which will set in one dimension the result of first lay (no parameters) and finally two dense lays\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Conv2D\n",
        "from tensorflow.keras.layers import Flatten\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, 3, activation='relu', input_shape=(30, 30, 1)))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dense(10))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BqifcMBLVAQh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 308
        },
        "outputId": "9d6bc658-b239-4c68-e4d6-405f2855698e"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_9\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_7 (Conv2D)            (None, 28, 28, 32)        320       \n",
            "_________________________________________________________________\n",
            "flatten_6 (Flatten)          (None, 25088)             0         \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 128)               3211392   \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 3,213,002\n",
            "Trainable params: 3,213,002\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3sRhXRXtQVc-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}